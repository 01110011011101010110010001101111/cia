{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/l2thzykn6k9489f9g899_cvc0000gn/T/ipykernel_13754/2617538202.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"cpu/NN/mnist_100_10.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Quantization code from Song Han's TinyML class\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max\n",
    "\n",
    "def get_quantization_scale_and_zero_point(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    get quantization scale for single tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [float] scale\n",
    "        [int] zero_point\n",
    "    \"\"\"\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    fp_max = fp_tensor.max()\n",
    "    fp_min = fp_tensor.min()\n",
    "\n",
    "    # scale\n",
    "    scale = (fp_max - fp_min) / (quantized_max - quantized_min)\n",
    "    # zero_point\n",
    "    zero_point = ((quantized_min - fp_min / scale))\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < quantized_min:\n",
    "        zero_point = quantized_min\n",
    "    elif zero_point > quantized_max:\n",
    "        zero_point = quantized_max\n",
    "    else: # convert from float to int using round()\n",
    "        zero_point = round(zero_point)\n",
    "    return scale, int(zero_point)\n",
    "\n",
    "def linear_quantize(fp_tensor, bitwidth, scale, zero_point, dtype=np.int8) -> np.array:\n",
    "    \"\"\"\n",
    "    linear quantization for single fp_tensor\n",
    "      from\n",
    "        r = fp_tensor = (quantized_tensor - zero_point) * scale\n",
    "      we have,\n",
    "        q = quantized_tensor = int(round(fp_tensor / scale)) + zero_point\n",
    "    :param tensor: [np.array] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :param scale: [float] scaling factor\n",
    "    :param zero_point: [int] the desired centroid of tensor values\n",
    "    :return:\n",
    "        [np.array] quantized tensor whose values are integers\n",
    "    \"\"\"\n",
    "    # assert(fp_tensor is np.array)\n",
    "    assert(isinstance(scale, float))\n",
    "    assert(isinstance(zero_point, int))\n",
    "\n",
    "    # scale the fp_tensor\n",
    "    scaled_tensor = fp_tensor/scale\n",
    "    # round the floating value to integer value\n",
    "    rounded_tensor = (np.round(scaled_tensor)) #.to(torch.int8)\n",
    "\n",
    "    # print(rounded_tensor.dtype)\n",
    "\n",
    "    # shift the rounded_tensor to make zero_point 0\n",
    "    shifted_tensor = rounded_tensor + zero_point\n",
    "\n",
    "    # clamp the shifted_tensor to lie in bitwidth-bit range\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    quantized_tensor = shifted_tensor.clip(quantized_min, quantized_max)\n",
    "    quantized_tensor = quantized_tensor.astype(np.int8)\n",
    "    return quantized_tensor\n",
    "\n",
    "def linear_quantize_feature(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    linear quantization for feature tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating feature to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [torch.(cuda.)Tensor] quantized tensor\n",
    "        [float] scale tensor\n",
    "        [int] zero point\n",
    "    \"\"\"\n",
    "    scale, zero_point = get_quantization_scale_and_zero_point(fp_tensor, bitwidth)\n",
    "    quantized_tensor = linear_quantize(fp_tensor, bitwidth, scale, zero_point)\n",
    "    return quantized_tensor, scale, zero_point\n",
    "\n",
    "checkpoint = torch.load(\"cpu/NN/mnist_100_10.pt\")\n",
    "# checkpoint = torch.load(\"./NN/MNIST_12_layers.pt\")\n",
    "\n",
    "weights_biases = {}\n",
    "\n",
    "for name, param in checkpoint.items():\n",
    "    weights_biases[name] = param.cpu().numpy()  # Convert to numpy array and store\n",
    "\n",
    "int8_quant = {}\n",
    "\n",
    "for key in weights_biases:\n",
    "    print(key)\n",
    "    int8_quant[key] = linear_quantize_feature(weights_biases[key], 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 64}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.Resize((10, 10)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Lambda(lambda x: torch.where(x > 0.7, torch.tensor(1.0), torch.tensor(0.0))),\n",
    "        transforms.Lambda(lambda x: x.view(-1))\n",
    "        ])\n",
    "\n",
    "def filter_0_and_1(dataset):\n",
    "    indices = [i for i, target in enumerate(dataset.targets) if target == 0 or target == 1]\n",
    "    dataset.targets = dataset.targets[indices]\n",
    "    dataset.data = dataset.data[indices]\n",
    "    return dataset\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "# test_dataset = filter_0_and_1(test_dataset)\n",
    "\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "# dataset2 = filter_0_and_1(dataset2)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = int8_quant[\"fc1.weight\"]\n",
    "m = test_dataset[0][0].numpy().astype(int)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "N = 100\n",
    "\n",
    "q = 2**16\n",
    "p = 2**10\n",
    "\n",
    "A = [np.random.randint(0, q, N) for _ in range(k)]\n",
    "s = [np.random.randint(0, 2, k)] * N\n",
    "s = np.array(s).T\n",
    "\n",
    "def polynomial_mult(s0, s1, size=N, base=q):\n",
    "    result = [0] * (size)\n",
    "\n",
    "    # Multiply the coefficients\n",
    "    for i in range(len(s0)):\n",
    "        for j in range(len(s1)):\n",
    "            if i + j < size:\n",
    "                result[i + j] += s0[i] * s1[j]\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i] % base\n",
    "\n",
    "    return result\n",
    "\n",
    "def enc():\n",
    "    # E = [1, 0, 1, -1] # \\in q\n",
    "    delta = q / p\n",
    "    # print(delta, LAMBDA, delta/LAMBDA)\n",
    "    # E = np.random.randint(-delta/LAMBDA, delta/LAMBDA, N)\n",
    "    delta_m = np.array(m) * delta\n",
    "\n",
    "    # B = np.array(delta_m) + np.array(E)\n",
    "    B = np.array(delta_m)\n",
    "\n",
    "    # breakpoint()\n",
    "    for idx in range(len(A)):\n",
    "        B += np.array(polynomial_mult(A[idx], s[idx], N, q))\n",
    "        B %= q\n",
    "\n",
    "    # B %= q\n",
    "    # print(B)\n",
    "    return B\n",
    "\n",
    "def dec(B, c = 1):\n",
    "    B_res = (np.array(B) * c) % q\n",
    "    for idx in range(len(A)):\n",
    "        B_res = (B_res - np.array(polynomial_mult((c**2 * A[idx]) % q, (s[idx]) % q, N, q))) % q\n",
    "    # can check bottom bits and add one if needed\n",
    "    return np.round(B_res / (q / p)) / c\n",
    "\n",
    "def dec2(A, B, s, N = 100):\n",
    "    B_res = (np.array(B)) % q\n",
    "    for idx in range(len(A)):\n",
    "        poly_m = np.array(polynomial_mult((A[idx]) % q, (s[idx]) % q, N, q))\n",
    "        # print(poly_m.shape)\n",
    "        B_res = (B_res - poly_m) % q\n",
    "    # can check bottom bits and add one if needed\n",
    "    return np.round(B_res / (q / p))%q\n",
    "\n",
    "\"\"\"\n",
    "Operations on ciphertext\n",
    "\"\"\"\n",
    "\n",
    "def add_ct(ct1, ct2):\n",
    "    return ct1 + ct2\n",
    "\n",
    "def add_constant(ct, c):\n",
    "    return ct + c * q/p\n",
    "\n",
    "def mul_constant(ct, A, c):\n",
    "    return ((c * ct) % (q)), ((c * A) % (q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "enc()\n",
    "print(np.array(dec(enc())).astype(int))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "newA = array1 = np.zeros((10, 500))\n",
    "\n",
    "newB = array2 = np.zeros((10, 1))\n",
    "\n",
    "newS = np.array([s.T[0]]*10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 100)\n",
      "(100, 500)\n",
      "(10, 100)\n",
      "[[47319 24744 34242 ... 57927 36854 57258]\n",
      " [ 3060  3425   922 ... 11973  8537 36519]\n",
      " [ 7508 10707 17614 ... 31409 35953 22040]\n",
      " ...\n",
      " [35984 22449 31734 ... 17440 14156 16343]\n",
      " [53874 62325 28935 ... 58392 20035 33686]\n",
      " [41437 58154  9353 ...  4619 55655 63223]]\n",
      "[[ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  2  2  2  2  2  1  1\n",
      "   1  1  1  1  1  2  2  2  1  1  1  0  1  2  2  2  2  2  1  1  0 -2 -1  2\n",
      "   3  2  2  2  2  1 -2 -4 -1  2  2  2  2  2  2  1 -1 -1  1  1  2  2  2  2\n",
      "   1  2  1  1  1  1  2  2  2  2  2  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  2  2  2  2  2  1  0\n",
      "   0  1  0  1  1  2  2  2  1 -1 -1  2  0 -1  1  2  2  2  1 -2  0  3 -1  0\n",
      "   2  2  2  2  1 -2  1  2 -3  0  1  2  2  2  0  0  2  1 -2  0  1  2  2  2\n",
      "   0  0  1  0 -1  1  2  2  2  2  1  1  0  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2  2  2  2  2  2\n",
      "   1  1  1  1  1  2  2  2  1 -1 -2  0  1  1  1  2  2  2  0 -3 -2  0  1  0\n",
      "   1  2  2  2  0  0  1  0  0  0  1  2  2  2  2  2  1  1  1  1  2  2  2  2\n",
      "   2  2  1  0  1  2  2  2  2  2  1  0 -1 -1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  2  2  2  2  2  2\n",
      "   1  1  1  1  1  2  2  2  1 -1 -1  1  1  0  1  2  2  2  0 -1  1  2  1  0\n",
      "   1  2  2  2  0 -1  0  0  1  1  1  2  2  2  0 -2 -3 -1  1  2  1  2  2  2\n",
      "   2  1  0  1  1  1  2  2  2  2  2  2  1  1  1  2  2  2  2  2  2  2  1  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1 -1  0  2  2  2  2  2  1  1\n",
      "  -1 -3  0  1  2  2  2  2  1  1  0 -2  1  1  1  2  2  2  1  2  1  0  1  1\n",
      "   1  2  2  2  2  2  2  1  2  1  1  2  2  1  1  0  1  1  0  0  1  2  2  2\n",
      "   0 -2 -1  0  0  1  2  2  2  2  1 -1  0  0  1  2  2  2  2  2  2  2  1  1\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  0  1  2  2  2  2  2  1  1\n",
      "   0  0  1  2  2  2  2  2  1  1  1  0 -1  0  2  2  2  2  1  2  2 -1 -3 -1\n",
      "   1  2  2  2  0  0  0  0  0  0  1  2  2  2  1 -1 -2  0  1  1  1  2  2  2\n",
      "   1  1  0  1  1  1  2  2  2  2  1  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1\n",
      "   0  0 -1 -1  1  2  2  2  1  0  1 -1 -3 -1  1  2  2  2  1  1  1  0  0  1\n",
      "   2  2  2  2  1  1  1  0  1  2  2  2  2  1  1  2  1  0  1  2  2  2  2  1\n",
      "   0  1  2  2  1  1  2  2  2  2  1 -1 -3 -2  0  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  0  0  2  2  2  2  2  2  1\n",
      "   0 -1  0  0  1  2  2  2  2  2  2  2  2  1  1  2  2  2  1  0 -1 -1  2  1\n",
      "   1  2  2  2  0 -2 -4  0  1  1  1  2  2  2  0 -2  0  1  0  0  1  2  2  1\n",
      "   0 -1  1  0 -1  0  2  2  2  2  1  1  1  1  1  1  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  0  0  0  1  2  2  2  2  1  1\n",
      "   1  1  1  1  1  2  2  2  1  1  1 -1  0  1  2  2  2  2  0  0  2  1  1  1\n",
      "   2  2  2  2 -1 -1  1  0 -1 -1  1  2  2  1  0  2  1  0  0  0  1  2  2  1\n",
      "   1  1  0  0  1  1  2  2  2  2  1  1  2  1  1  2  2  2  2  2  2  2  1  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  0  0  1  2  2  2  2  1 -1\n",
      "   1  2  1  0  1  2  2  2  0  1  1  0  1  0  1  2  2  2  2  2  0  0  1  1\n",
      "   1  2  2  2  1  2  1  1  1  0  1  2  2  2  0  0  0  1  0  0  1  2  2  2\n",
      "   0 -3 -1  0  0  0  2  2  2  2  1  0  0  0  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]]\n",
      "[[54883 51174 21518 ... 59898  9755  8434]\n",
      " [22257 17283 39162 ... 38878 21538 27362]\n",
      " [23220 19274  4753 ... 26758 40262 39672]\n",
      " ...\n",
      " [31845  4246 49309 ... 27211   566 56848]\n",
      " [28860  7514 23982 ... 30750 15498 59786]\n",
      " [34870 31990  8476 ... 58073 26144 35695]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array(A)\n",
    "type(A)\n",
    "print(A.shape)\n",
    "print(A.T.shape)\n",
    "print(weights.shape)\n",
    "\n",
    "newA = np.dot(weights, A.T)%q\n",
    "newA.shape\n",
    "\n",
    "print(A.T)\n",
    "print(weights)\n",
    "print(newA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(10, 1)\n",
      "(500, 10)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "[[4757037.]\n",
      " [4170844.]\n",
      " [4821920.]\n",
      " [4644913.]\n",
      " [4221736.]\n",
      " [4557902.]\n",
      " [4494688.]\n",
      " [4166521.]\n",
      " [4304344.]\n",
      " [4133439.]]\n"
     ]
    }
   ],
   "source": [
    "b = enc().reshape((100, 1))\n",
    "print(b.shape)\n",
    "newB = np.dot(weights, b)\n",
    "print(newB.shape)\n",
    "print(newS.shape)\n",
    "\n",
    "print(newS)\n",
    "print(newB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n",
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  67., 1007.,  598.,  699.,  491.,  420.,  779.,  427.,  361.,\n",
       "        378.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(newA.T.shape)\n",
    "print(newB.T[0].shape)\n",
    "dec2(newA.T, newB.T[0], newS, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(10, 100)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  2  2  2  2  2  1  1\n",
      "   1  1  1  1  1  2  2  2  1  1  1  0  1  2  2  2  2  2  1  1  0 -2 -1  2\n",
      "   3  2  2  2  2  1 -2 -4 -1  2  2  2  2  2  2  1 -1 -1  1  1  2  2  2  2\n",
      "   1  2  1  1  1  1  2  2  2  2  2  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  2  2  2  2  2  1  0\n",
      "   0  1  0  1  1  2  2  2  1 -1 -1  2  0 -1  1  2  2  2  1 -2  0  3 -1  0\n",
      "   2  2  2  2  1 -2  1  2 -3  0  1  2  2  2  0  0  2  1 -2  0  1  2  2  2\n",
      "   0  0  1  0 -1  1  2  2  2  2  1  1  0  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2  2  2  2  2  2\n",
      "   1  1  1  1  1  2  2  2  1 -1 -2  0  1  1  1  2  2  2  0 -3 -2  0  1  0\n",
      "   1  2  2  2  0  0  1  0  0  0  1  2  2  2  2  2  1  1  1  1  2  2  2  2\n",
      "   2  2  1  0  1  2  2  2  2  2  1  0 -1 -1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  2  2  2  2  2  2\n",
      "   1  1  1  1  1  2  2  2  1 -1 -1  1  1  0  1  2  2  2  0 -1  1  2  1  0\n",
      "   1  2  2  2  0 -1  0  0  1  1  1  2  2  2  0 -2 -3 -1  1  2  1  2  2  2\n",
      "   2  1  0  1  1  1  2  2  2  2  2  2  1  1  1  2  2  2  2  2  2  2  1  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1 -1  0  2  2  2  2  2  1  1\n",
      "  -1 -3  0  1  2  2  2  2  1  1  0 -2  1  1  1  2  2  2  1  2  1  0  1  1\n",
      "   1  2  2  2  2  2  2  1  2  1  1  2  2  1  1  0  1  1  0  0  1  2  2  2\n",
      "   0 -2 -1  0  0  1  2  2  2  2  1 -1  0  0  1  2  2  2  2  2  2  2  1  1\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  0  1  2  2  2  2  2  1  1\n",
      "   0  0  1  2  2  2  2  2  1  1  1  0 -1  0  2  2  2  2  1  2  2 -1 -3 -1\n",
      "   1  2  2  2  0  0  0  0  0  0  1  2  2  2  1 -1 -2  0  1  1  1  2  2  2\n",
      "   1  1  0  1  1  1  2  2  2  2  1  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1\n",
      "   0  0 -1 -1  1  2  2  2  1  0  1 -1 -3 -1  1  2  2  2  1  1  1  0  0  1\n",
      "   2  2  2  2  1  1  1  0  1  2  2  2  2  1  1  2  1  0  1  2  2  2  2  1\n",
      "   0  1  2  2  1  1  2  2  2  2  1 -1 -3 -2  0  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  0  0  2  2  2  2  2  2  1\n",
      "   0 -1  0  0  1  2  2  2  2  2  2  2  2  1  1  2  2  2  1  0 -1 -1  2  1\n",
      "   1  2  2  2  0 -2 -4  0  1  1  1  2  2  2  0 -2  0  1  0  0  1  2  2  1\n",
      "   0 -1  1  0 -1  0  2  2  2  2  1  1  1  1  1  1  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  0  0  0  1  2  2  2  2  1  1\n",
      "   1  1  1  1  1  2  2  2  1  1  1 -1  0  1  2  2  2  2  0  0  2  1  1  1\n",
      "   2  2  2  2 -1 -1  1  0 -1 -1  1  2  2  1  0  2  1  0  0  0  1  2  2  1\n",
      "   1  1  0  0  1  1  2  2  2  2  1  1  2  1  1  2  2  2  2  2  2  2  1  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  0  0  1  2  2  2  2  1 -1\n",
      "   1  2  1  0  1  2  2  2  0  1  1  0  1  0  1  2  2  2  2  2  0  0  1  1\n",
      "   1  2  2  2  1  2  1  1  1  0  1  2  2  2  0  0  0  1  0  0  1  2  2  2\n",
      "   0 -3 -1  0  0  0  2  2  2  2  1  0  0  0  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [ 1],\n",
       "       [ 6],\n",
       "       [13],\n",
       "       [ 1],\n",
       "       [14],\n",
       "       [ 5],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [ 5]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.reshape((100,1)).shape)\n",
    "print(weights.shape)\n",
    "print(m)\n",
    "print(weights)\n",
    "np.dot(weights, m.reshape((100,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6205_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
