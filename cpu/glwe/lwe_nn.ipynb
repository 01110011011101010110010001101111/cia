{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/l2thzykn6k9489f9g899_cvc0000gn/T/ipykernel_66012/2617538202.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"cpu/NN/mnist_100_10.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Quantization code from Song Han's TinyML class\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max\n",
    "\n",
    "def get_quantization_scale_and_zero_point(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    get quantization scale for single tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [float] scale\n",
    "        [int] zero_point\n",
    "    \"\"\"\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    fp_max = fp_tensor.max()\n",
    "    fp_min = fp_tensor.min()\n",
    "\n",
    "    # scale\n",
    "    scale = (fp_max - fp_min) / (quantized_max - quantized_min)\n",
    "    # zero_point\n",
    "    zero_point = ((quantized_min - fp_min / scale))\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < quantized_min:\n",
    "        zero_point = quantized_min\n",
    "    elif zero_point > quantized_max:\n",
    "        zero_point = quantized_max\n",
    "    else: # convert from float to int using round()\n",
    "        zero_point = round(zero_point)\n",
    "    return scale, int(zero_point)\n",
    "\n",
    "def linear_quantize(fp_tensor, bitwidth, scale, zero_point, dtype=np.int8) -> np.array:\n",
    "    \"\"\"\n",
    "    linear quantization for single fp_tensor\n",
    "      from\n",
    "        r = fp_tensor = (quantized_tensor - zero_point) * scale\n",
    "      we have,\n",
    "        q = quantized_tensor = int(round(fp_tensor / scale)) + zero_point\n",
    "    :param tensor: [np.array] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :param scale: [float] scaling factor\n",
    "    :param zero_point: [int] the desired centroid of tensor values\n",
    "    :return:\n",
    "        [np.array] quantized tensor whose values are integers\n",
    "    \"\"\"\n",
    "    # assert(fp_tensor is np.array)\n",
    "    assert(isinstance(scale, float))\n",
    "    assert(isinstance(zero_point, int))\n",
    "\n",
    "    # scale the fp_tensor\n",
    "    scaled_tensor = fp_tensor/scale\n",
    "    # round the floating value to integer value\n",
    "    rounded_tensor = (np.round(scaled_tensor)) #.to(torch.int8)\n",
    "\n",
    "    # print(rounded_tensor.dtype)\n",
    "\n",
    "    # shift the rounded_tensor to make zero_point 0\n",
    "    shifted_tensor = rounded_tensor + zero_point\n",
    "\n",
    "    # clamp the shifted_tensor to lie in bitwidth-bit range\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    quantized_tensor = shifted_tensor.clip(quantized_min, quantized_max)\n",
    "    quantized_tensor = quantized_tensor.astype(np.int8)\n",
    "    return quantized_tensor\n",
    "\n",
    "def linear_quantize_feature(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    linear quantization for feature tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating feature to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [torch.(cuda.)Tensor] quantized tensor\n",
    "        [float] scale tensor\n",
    "        [int] zero point\n",
    "    \"\"\"\n",
    "    scale, zero_point = get_quantization_scale_and_zero_point(fp_tensor, bitwidth)\n",
    "    quantized_tensor = linear_quantize(fp_tensor, bitwidth, scale, zero_point)\n",
    "    return quantized_tensor, scale, zero_point\n",
    "\n",
    "checkpoint = torch.load(\"cpu/NN/mnist_100_10.pt\")\n",
    "# checkpoint = torch.load(\"./NN/MNIST_12_layers.pt\")\n",
    "\n",
    "weights_biases = {}\n",
    "\n",
    "for name, param in checkpoint.items():\n",
    "    weights_biases[name] = param.cpu().numpy()  # Convert to numpy array and store\n",
    "\n",
    "int8_quant = {}\n",
    "\n",
    "for key in weights_biases:\n",
    "    print(key)\n",
    "    int8_quant[key] = linear_quantize_feature(weights_biases[key], 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 64}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.Resize((10, 10)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Lambda(lambda x: torch.where(x > 0.7, torch.tensor(1.0), torch.tensor(0.0))),\n",
    "        transforms.Lambda(lambda x: x.view(-1))\n",
    "        ])\n",
    "\n",
    "def filter_0_and_1(dataset):\n",
    "    indices = [i for i, target in enumerate(dataset.targets) if target == 0 or target == 1]\n",
    "    dataset.targets = dataset.targets[indices]\n",
    "    dataset.data = dataset.data[indices]\n",
    "    return dataset\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "# test_dataset = filter_0_and_1(test_dataset)\n",
    "\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "# dataset2 = filter_0_and_1(dataset2)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = int8_quant[\"fc1.weight\"]\n",
    "m = test_dataset[0][0].numpy().astype(int)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "N = 100\n",
    "\n",
    "q = 2**16\n",
    "p = 2**10\n",
    "\n",
    "A = [np.random.randint(0, q, k) for _ in range(N)]\n",
    "s = np.random.randint(0, 2, k)\n",
    "A = np.array(A)\n",
    "\n",
    "def polynomial_mult(s0, s1, size=N, base=q):\n",
    "    result = [0] * (size)\n",
    "\n",
    "    # Multiply the coefficients\n",
    "    for i in range(len(s0)):\n",
    "        for j in range(len(s1)):\n",
    "            if i + j < size:\n",
    "                result[i + j] += s0[i] * s1[j]\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i] % base\n",
    "\n",
    "    return result\n",
    "\n",
    "def lwe_enc():\n",
    "    # E = [1, 0, 1, -1] # \\in q\n",
    "    LAMBDA = 64\n",
    "    delta = q / p\n",
    "    # print(delta, LAMBDA, delta/LAMBDA)\n",
    "    E = np.random.randint(0, delta/LAMBDA, N)\n",
    "    delta_m = np.array(m) * delta\n",
    "\n",
    "    B = (np.array(delta_m) + E)\n",
    "\n",
    "    # breakpoint()\n",
    "    for idx in range(N):\n",
    "        for j in range(k):\n",
    "            B[idx] += A[idx][j] * s[j]\n",
    "            B[idx] %= q\n",
    "\n",
    "    return B\n",
    "\n",
    "def dec_lwe(A, B, s, N=100):\n",
    "    for idx in range(N):\n",
    "        for j in range(k):\n",
    "            B[idx] -= A[idx][j] * s[j]\n",
    "            B %= q\n",
    "    # can check bottom bits and add one if needed\n",
    "    return np.round(B / (q / p)) % q\n",
    "\n",
    "\"\"\"\n",
    "Operations on ciphertext\n",
    "\"\"\"\n",
    "\n",
    "def add_ct(ct1, ct2, A1, A2):\n",
    "    return ct1 + ct2, A1 + A2\n",
    "\n",
    "def add_constant(ct, c):\n",
    "    return ct + c * q/p\n",
    "\n",
    "def mul_constant(ct, A, c):\n",
    "    return ((c * ct) % (q)), ((c * A) % (q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 12., 12., 12.,\n",
       "       12., 12.,  0.,  0.,  0.,  0.,  0., 12., 12.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., 12., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "       12., 12.,  0.,  0.,  0.,  0.,  0.,  0., 12., 12., 12.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., 12., 12., 12.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m)\n",
    "b = lwe_enc()\n",
    "newb, newA = mul_constant(b, A, 12)\n",
    "dec_lwe(newA, newb, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.],\n",
       "       [ 1.],\n",
       "       [ 6.],\n",
       "       [13.],\n",
       "       [ 1.],\n",
       "       [14.],\n",
       "       [ 5.],\n",
       "       [ 8.],\n",
       "       [13.],\n",
       "       [ 5.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newA = np.dot(weights, A) % q\n",
    "newB = np.dot(weights, b.reshape(100, 1)) % q\n",
    "\n",
    "dec_lwe(newA, newB, s, N = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [ 1],\n",
       "       [ 6],\n",
       "       [13],\n",
       "       [ 1],\n",
       "       [14],\n",
       "       [ 5],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [ 5]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(weights, m.reshape(100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/ruth/6.2050/fpga-project/enc_Asm.pkl.\n",
      "Output image saved at A.mem\n",
      "Output image saved at s.mem\n",
      "Output image saved at pt.mem\n",
      "Output image saved at b.mem\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = \"/Users/ruth/6.2050/fpga-project/enc_Asm.pkl\"\n",
    "\n",
    "if(True):\n",
    "    data = {'m': m, 's': s, 'A': A}\n",
    "\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {pickle_file}.\")\n",
    "else:\n",
    "    with open('/Users/ruth/6.2050/fpga-project/Asm.pkl', 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    A = loaded_data[\"A\"]\n",
    "    s = loaded_data[\"s\"]\n",
    "    m = loaded_data[\"m\"]\n",
    "\n",
    "def make_num(list, bits):\n",
    "    number = 0\n",
    "    #for i, val in enumerate(reversed(list)):\n",
    "        #number += (val << i*bits)\n",
    "    for i, val in enumerate(list):\n",
    "        number += (val << i*bits)\n",
    "    return number\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/A.mem', 'w') as f:\n",
    "    for x in range(N):\n",
    "        for y in range(0, k, 2):\n",
    "            f.write(f'{make_num(A[x][y:y+2], 16):X}\\n')\n",
    "print('Output image saved at A.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/s.mem', 'w') as f:\n",
    "    for y in range(0, k, 2):\n",
    "        f.write(f'{make_num(s[y:y+2], 1):X}\\n')\n",
    "print('Output image saved at s.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/pt.mem', 'w') as f:\n",
    "    for y in range(0, N, 2):\n",
    "        f.write(f'{make_num(m[y:y+2], 1):X}\\n')\n",
    "print('Output image saved at pt.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/b.mem', 'w') as f:\n",
    "    for x in range(k):\n",
    "        for y in range(0, N, 2):\n",
    "            f.write(f'{0}\\n')\n",
    "print('Output image saved at b.mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n",
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 356.,  118.,  153.,  782.,  282., 1009.,  123.,  789.,  986.,\n",
       "        266.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(newA.T.shape)\n",
    "print(newB.T[0].shape)\n",
    "dec2(newA.T, newB.T[0], newS, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(10, 100)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  2  2  2  2  2  1  1\n",
      "   1  1  1  1  1  2  2  2  1  1  1  0  1  2  2  2  2  2  1  1  0 -2 -1  2\n",
      "   3  2  2  2  2  1 -2 -4 -1  2  2  2  2  2  2  1 -1 -1  1  1  2  2  2  2\n",
      "   1  2  1  1  1  1  2  2  2  2  2  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  2  2  2  2  2  1  0\n",
      "   0  1  0  1  1  2  2  2  1 -1 -1  2  0 -1  1  2  2  2  1 -2  0  3 -1  0\n",
      "   2  2  2  2  1 -2  1  2 -3  0  1  2  2  2  0  0  2  1 -2  0  1  2  2  2\n",
      "   0  0  1  0 -1  1  2  2  2  2  1  1  0  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2  2  2  2  2  2\n",
      "   1  1  1  1  1  2  2  2  1 -1 -2  0  1  1  1  2  2  2  0 -3 -2  0  1  0\n",
      "   1  2  2  2  0  0  1  0  0  0  1  2  2  2  2  2  1  1  1  1  2  2  2  2\n",
      "   2  2  1  0  1  2  2  2  2  2  1  0 -1 -1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  2  2  2  2  2  2\n",
      "   1  1  1  1  1  2  2  2  1 -1 -1  1  1  0  1  2  2  2  0 -1  1  2  1  0\n",
      "   1  2  2  2  0 -1  0  0  1  1  1  2  2  2  0 -2 -3 -1  1  2  1  2  2  2\n",
      "   2  1  0  1  1  1  2  2  2  2  2  2  1  1  1  2  2  2  2  2  2  2  1  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  1 -1  0  2  2  2  2  2  1  1\n",
      "  -1 -3  0  1  2  2  2  2  1  1  0 -2  1  1  1  2  2  2  1  2  1  0  1  1\n",
      "   1  2  2  2  2  2  2  1  2  1  1  2  2  1  1  0  1  1  0  0  1  2  2  2\n",
      "   0 -2 -1  0  0  1  2  2  2  2  1 -1  0  0  1  2  2  2  2  2  2  2  1  1\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  0  1  2  2  2  2  2  1  1\n",
      "   0  0  1  2  2  2  2  2  1  1  1  0 -1  0  2  2  2  2  1  2  2 -1 -3 -1\n",
      "   1  2  2  2  0  0  0  0  0  0  1  2  2  2  1 -1 -2  0  1  1  1  2  2  2\n",
      "   1  1  0  1  1  1  2  2  2  2  1  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1\n",
      "   0  0 -1 -1  1  2  2  2  1  0  1 -1 -3 -1  1  2  2  2  1  1  1  0  0  1\n",
      "   2  2  2  2  1  1  1  0  1  2  2  2  2  1  1  2  1  0  1  2  2  2  2  1\n",
      "   0  1  2  2  1  1  2  2  2  2  1 -1 -3 -2  0  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  0  0  2  2  2  2  2  2  1\n",
      "   0 -1  0  0  1  2  2  2  2  2  2  2  2  1  1  2  2  2  1  0 -1 -1  2  1\n",
      "   1  2  2  2  0 -2 -4  0  1  1  1  2  2  2  0 -2  0  1  0  0  1  2  2  1\n",
      "   0 -1  1  0 -1  0  2  2  2  2  1  1  1  1  1  1  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  1  0  0  0  1  2  2  2  2  1  1\n",
      "   1  1  1  1  1  2  2  2  1  1  1 -1  0  1  2  2  2  2  0  0  2  1  1  1\n",
      "   2  2  2  2 -1 -1  1  0 -1 -1  1  2  2  1  0  2  1  0  0  0  1  2  2  1\n",
      "   1  1  0  0  1  1  2  2  2  2  1  1  2  1  1  2  2  2  2  2  2  2  1  2\n",
      "   2  2  2  2]\n",
      " [ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  0  0  1  2  2  2  2  1 -1\n",
      "   1  2  1  0  1  2  2  2  0  1  1  0  1  0  1  2  2  2  2  2  0  0  1  1\n",
      "   1  2  2  2  1  2  1  1  1  0  1  2  2  2  0  0  0  1  0  0  1  2  2  2\n",
      "   0 -3 -1  0  0  0  2  2  2  2  1  0  0  0  1  2  2  2  2  2  2  2  2  2\n",
      "   2  2  2  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [ 1],\n",
       "       [ 6],\n",
       "       [13],\n",
       "       [ 1],\n",
       "       [14],\n",
       "       [ 5],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [ 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.reshape((100,1)).shape)\n",
    "print(weights.shape)\n",
    "print(m)\n",
    "print(weights)\n",
    "np.dot(weights, m.reshape((100,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "(500,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "v = 5\n",
    "print(weights[:, v])\n",
    "print(A.T[v, :].shape)\n",
    "print(m[v])\n",
    "A_v = np.dot(weights[:, v].reshape((10, 1)), A.T[v, :].reshape(1, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_v = np.dot(weights[:, v].reshape((10, 1)), m[v].reshape(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[32671.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m[v])\n",
    "b_v = [enc()[v]]\n",
    "b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([423.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec2(A[:, v].reshape(500, 1), [enc()[v]], s[:, v].reshape(500, 1), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T[v, :].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 6], [3, 5, 7], [4, 5, 3, 0]]\n"
     ]
    }
   ],
   "source": [
    "def sample_extraction(h = 0):\n",
    "\n",
    "    N = 2\n",
    "    k = 2\n",
    "\n",
    "    res_ct = [[1, 4, 6], [3, 5, 7]]\n",
    "    b = 0\n",
    "    h = 1\n",
    "\n",
    "    res_ct.append([0]*k*N)\n",
    "\n",
    "    for i in range(k):\n",
    "        for j in range(h+1): \n",
    "            res_ct[N][i+j] = res_ct[i][h-j]\n",
    "    for i in range(k):\n",
    "        for j in range(h+1, N): \n",
    "            res_ct[N][i+j] = res_ct[i][h-j + N]\n",
    "\n",
    "    print(res_ct)\n",
    "    b = b\n",
    "\n",
    "sample_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6205_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
