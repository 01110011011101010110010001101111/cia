{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/l2thzykn6k9489f9g899_cvc0000gn/T/ipykernel_37183/2617538202.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"cpu/NN/mnist_100_10.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Quantization code from Song Han's TinyML class\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max\n",
    "\n",
    "def get_quantization_scale_and_zero_point(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    get quantization scale for single tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [float] scale\n",
    "        [int] zero_point\n",
    "    \"\"\"\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    fp_max = fp_tensor.max()\n",
    "    fp_min = fp_tensor.min()\n",
    "\n",
    "    # scale\n",
    "    scale = (fp_max - fp_min) / (quantized_max - quantized_min)\n",
    "    # zero_point\n",
    "    zero_point = ((quantized_min - fp_min / scale))\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < quantized_min:\n",
    "        zero_point = quantized_min\n",
    "    elif zero_point > quantized_max:\n",
    "        zero_point = quantized_max\n",
    "    else: # convert from float to int using round()\n",
    "        zero_point = round(zero_point)\n",
    "    return scale, int(zero_point)\n",
    "\n",
    "def linear_quantize(fp_tensor, bitwidth, scale, zero_point, dtype=np.int8) -> np.array:\n",
    "    \"\"\"\n",
    "    linear quantization for single fp_tensor\n",
    "      from\n",
    "        r = fp_tensor = (quantized_tensor - zero_point) * scale\n",
    "      we have,\n",
    "        q = quantized_tensor = int(round(fp_tensor / scale)) + zero_point\n",
    "    :param tensor: [np.array] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :param scale: [float] scaling factor\n",
    "    :param zero_point: [int] the desired centroid of tensor values\n",
    "    :return:\n",
    "        [np.array] quantized tensor whose values are integers\n",
    "    \"\"\"\n",
    "    # assert(fp_tensor is np.array)\n",
    "    assert(isinstance(scale, float))\n",
    "    assert(isinstance(zero_point, int))\n",
    "\n",
    "    # scale the fp_tensor\n",
    "    scaled_tensor = fp_tensor/scale\n",
    "    # round the floating value to integer value\n",
    "    rounded_tensor = (np.round(scaled_tensor)) #.to(torch.int8)\n",
    "\n",
    "    # print(rounded_tensor.dtype)\n",
    "\n",
    "    # shift the rounded_tensor to make zero_point 0\n",
    "    shifted_tensor = rounded_tensor + zero_point\n",
    "\n",
    "    # clamp the shifted_tensor to lie in bitwidth-bit range\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    quantized_tensor = shifted_tensor.clip(quantized_min, quantized_max)\n",
    "    quantized_tensor = quantized_tensor.astype(np.int8)\n",
    "    return quantized_tensor\n",
    "\n",
    "def linear_quantize_feature(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    linear quantization for feature tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating feature to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [torch.(cuda.)Tensor] quantized tensor\n",
    "        [float] scale tensor\n",
    "        [int] zero point\n",
    "    \"\"\"\n",
    "    scale, zero_point = get_quantization_scale_and_zero_point(fp_tensor, bitwidth)\n",
    "    quantized_tensor = linear_quantize(fp_tensor, bitwidth, scale, zero_point)\n",
    "    return quantized_tensor, scale, zero_point\n",
    "\n",
    "checkpoint = torch.load(\"cpu/NN/mnist_100_10.pt\")\n",
    "# checkpoint = torch.load(\"./NN/MNIST_12_layers.pt\")\n",
    "\n",
    "weights_biases = {}\n",
    "\n",
    "for name, param in checkpoint.items():\n",
    "    weights_biases[name] = param.cpu().numpy()  # Convert to numpy array and store\n",
    "\n",
    "int8_quant = {}\n",
    "\n",
    "for key in weights_biases:\n",
    "    print(key)\n",
    "    int8_quant[key] = linear_quantize_feature(weights_biases[key], 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 64}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.Resize((10, 10)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Lambda(lambda x: torch.where(x > 0.7, torch.tensor(1.0), torch.tensor(0.0))),\n",
    "        transforms.Lambda(lambda x: x.view(-1))\n",
    "        ])\n",
    "\n",
    "def filter_0_and_1(dataset):\n",
    "    indices = [i for i, target in enumerate(dataset.targets) if target == 0 or target == 1]\n",
    "    dataset.targets = dataset.targets[indices]\n",
    "    dataset.data = dataset.data[indices]\n",
    "    return dataset\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "# test_dataset = filter_0_and_1(test_dataset)\n",
    "\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "# dataset2 = filter_0_and_1(dataset2)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = int8_quant[\"fc1.weight\"]\n",
    "m = test_dataset[0][0].numpy().astype(int)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "N = 100\n",
    "\n",
    "q = 2**16\n",
    "p = 2**10\n",
    "\n",
    "A = [np.random.randint(0, q, k) for _ in range(N)]\n",
    "s = np.random.randint(0, 2, k)\n",
    "A = np.array(A)\n",
    "\n",
    "def polynomial_mult(s0, s1, size=N, base=q):\n",
    "    result = [0] * (size)\n",
    "\n",
    "    # Multiply the coefficients\n",
    "    for i in range(len(s0)):\n",
    "        for j in range(len(s1)):\n",
    "            if i + j < size:\n",
    "                result[i + j] += s0[i] * s1[j]\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        result[i] = result[i] % base\n",
    "\n",
    "    return result\n",
    "\n",
    "def lwe_enc():\n",
    "    # E = [1, 0, 1, -1] # \\in q\n",
    "    LAMBDA = 64\n",
    "    delta = q / p\n",
    "    # print(delta, LAMBDA, delta/LAMBDA)\n",
    "    E = np.random.randint(0, delta/LAMBDA, N)\n",
    "    delta_m = np.array(m) * delta\n",
    "\n",
    "    B = (np.array(delta_m) + E)\n",
    "\n",
    "    # breakpoint()\n",
    "    for idx in range(N):\n",
    "        for j in range(k):\n",
    "            B[idx] += A[idx][j] * s[j]\n",
    "            B[idx] %= q\n",
    "\n",
    "    return B\n",
    "\n",
    "def dec_lwe(A, B, s, N=100):\n",
    "    for idx in range(N):\n",
    "        for j in range(k):\n",
    "            B[idx] -= A[idx][j] * s[j]\n",
    "            B %= q\n",
    "    # can check bottom bits and add one if needed\n",
    "    return np.round(B / (q / p)) % q\n",
    "\n",
    "\"\"\"\n",
    "Operations on ciphertext\n",
    "\"\"\"\n",
    "\n",
    "def add_ct(ct1, ct2, A1, A2):\n",
    "    return ct1 + ct2, A1 + A2\n",
    "\n",
    "def add_constant(ct, c):\n",
    "    return ct + c * q/p\n",
    "\n",
    "def mul_constant(ct, A, c):\n",
    "    return ((c * ct) % (q)), ((c * A) % (q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 12., 12., 12.,\n",
       "       12., 12.,  0.,  0.,  0.,  0.,  0., 12., 12.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., 12., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "       12., 12.,  0.,  0.,  0.,  0.,  0.,  0., 12., 12., 12.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., 12., 12., 12.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m)\n",
    "b = lwe_enc()\n",
    "newb, newA = mul_constant(b, A, 12)\n",
    "dec_lwe(newA, newb, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newA = np.dot(weights, A) % q\n",
    "newB = np.dot(weights, b.reshape(100, 1)) % q\n",
    "\n",
    "# dec_lwe(newA, newB, s, N = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  6, 13,  1, 14,  5,  8, 13,  5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_M = np.dot(weights, m.reshape(100, 1)).reshape(10)\n",
    "new_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m pickle_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ruth/6.2050/fpga-project/nn_Asmb.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m: m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m: s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnn_A\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: b}\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     11\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(data, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_A' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "N=100\n",
    "\n",
    "pickle_file = \"/Users/ruth/6.2050/fpga-project/nn_Asmb.pkl\"\n",
    "\n",
    "if(True):\n",
    "    data = {'m': m, 's': s, 'A': nn_A, 'b': b}\n",
    "\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {pickle_file}.\")\n",
    "else:\n",
    "    with open('/Users/ruth/6.2050/fpga-project/Asm.pkl', 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    A = loaded_data[\"A\"]\n",
    "    s = loaded_data[\"s\"]\n",
    "    m = loaded_data[\"m\"]\n",
    "\n",
    "def make_num(list, bits):\n",
    "    number = 0\n",
    "    #for i, val in enumerate(reversed(list)):\n",
    "        #number += (val << i*bits)\n",
    "    for i, val in enumerate(list):\n",
    "        number += (val << i*bits)\n",
    "    return number\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/A.mem', 'w') as f:\n",
    "    for x in range(N):\n",
    "        for y in range(0, k, 2):\n",
    "            f.write(f'{make_num(A[x][y:y+2], 16):X}\\n')\n",
    "print('Output image saved at A.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/s.mem', 'w') as f:\n",
    "    for y in range(0, k, 2):\n",
    "        f.write(f'{make_num(s[y:y+2], 1):X}\\n')\n",
    "print('Output image saved at s.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/pt.mem', 'w') as f:\n",
    "    for y in range(0, N):\n",
    "        f.write(f'{make_num([m[y]], 1):X}\\n')\n",
    "print('Output image saved at pt.mem')\n",
    "\n",
    "b = b.astype(int)\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/b.mem', 'w') as f:\n",
    "    for x in range(N):\n",
    "        f.write(f'{b[x]:X}\\n')\n",
    "print('Output image saved at b.mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/ruth/6.2050/fpga-project/dec_Asmb.pkl.\n",
      "Output image saved at A.mem\n",
      "Output image saved at s.mem\n",
      "Output image saved at pt.mem\n",
      "63332\n",
      "59839\n",
      "37459\n",
      "54843\n",
      "57837\n",
      "57044\n",
      "25771\n",
      "35349\n",
      "36422\n",
      "54328\n",
      "Output image saved at b.mem\n",
      "[63332 59839 37459 54843 57837 57044 25771 35349 36422 54328]\n"
     ]
    }
   ],
   "source": [
    "pickle_file = \"/Users/ruth/6.2050/fpga-project/dec_Asmb.pkl\"\n",
    "\n",
    "N = 10\n",
    "\n",
    "if(True):\n",
    "    data = {'m': new_M, 's': s, 'A': newA, \"b\": newB}\n",
    "\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {pickle_file}.\")\n",
    "else:\n",
    "    with open('/Users/ruth/6.2050/fpga-project/Asm.pkl', 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    A = loaded_data[\"A\"]\n",
    "    s = loaded_data[\"s\"]\n",
    "    m = loaded_data[\"m\"]\n",
    "\n",
    "def make_num(list, bits):\n",
    "    number = 0\n",
    "    for i, val in enumerate(list):\n",
    "        number += (val << i*bits)\n",
    "    return number\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/A.mem', 'w') as f:\n",
    "    for x in range(N):\n",
    "        for y in range(0, k, 2):\n",
    "            f.write(f'{make_num(newA[x][y:y+2], 16):X}\\n')\n",
    "print('Output image saved at A.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/s.mem', 'w') as f:\n",
    "    for y in range(0, k, 2):\n",
    "        f.write(f'{make_num(s[y:y+2], 1):X}\\n')\n",
    "print('Output image saved at s.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/pt.mem', 'w') as f:\n",
    "    for y in range(0, N):\n",
    "        f.write(f'{make_num([new_M[y]], 1):X}\\n')\n",
    "print('Output image saved at pt.mem')\n",
    "\n",
    "newB = newB.reshape(10).astype(int)\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/b.mem', 'w') as f:\n",
    "    for x in range(N):\n",
    "        f.write(f'{newB[x]:X}\\n')\n",
    "print('Output image saved at b.mem')\n",
    "\n",
    "print(newB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output image saved at nn.mem\n",
      "Output image saved at biases.mem\n"
     ]
    }
   ],
   "source": [
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/nn.mem', 'w') as f:\n",
    "    \n",
    "    for y in range(100):\n",
    "        for x in range(10):\n",
    "            f.write(f'{weights[x][y]%8:X}\\n')\n",
    "\n",
    "print('Output image saved at nn.mem')\n",
    "\n",
    "biases = int8_quant[\"fc1.bias\"]\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/biases.mem', 'w') as f:\n",
    "    \n",
    "    for x in range(10):\n",
    "        f.write(f'{biases[x]%8:X}\\n')\n",
    "\n",
    "print('Output image saved at biases.mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 502)\n",
      "Data saved to /Users/ruth/6.2050/fpga-project/nn_Asmbnn.pkl.\n",
      "Output image saved at A.mem\n",
      "Output image saved at s.mem\n",
      "Output image saved at pt.mem\n",
      "Output image saved at b.mem\n",
      "[13024 21428 58183 65357 28990 29621 43803 24930 33551 60489  1902 26220\n",
      " 24318 35089 14492  9963  7116 60617 36329 28418 42640 56014 22735 10489\n",
      " 29499 32334 31074 35953 42967 20426 34898 57658 13964 62367 64827 38811\n",
      " 27626  9635 18395 62679 44146 21821 31397 10575 38856 63216 42725  9739\n",
      "  2839 21104 53856  3587 30637 55027 63228 54268 64856    84 47189 10271\n",
      " 12765 28951  6962 53148 60440 56089 19927 55128 17652 12548 59903 15465\n",
      "  5023 58893 22431 22444 31497 42816 45694 12459  1783 48371 36094 29660\n",
      " 34342 40726 32490 59336 64764 45888 50451 42741 23221 34954 43803 29681\n",
      " 35717 30921 11178 29562]\n",
      "[[ 1646 44401 31295 ... 57867 13024     0]\n",
      " [45642 51371  4208 ...  4528 21428     0]\n",
      " [55371  4285 12767 ... 31955 58183     0]\n",
      " ...\n",
      " [35872 33764 41191 ... 46707 30921     0]\n",
      " [45248  5029 36112 ... 57105 11178     0]\n",
      " [64708 36808 28491 ... 56161 29562     0]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "nn_A = np.concatenate((A, b.reshape(100, 1)), axis=1)\n",
    "nn_A = np.concatenate((nn_A, np.zeros((100, 1))), axis=1)\n",
    "nn_A = nn_A.astype(int)\n",
    "print(nn_A.shape)\n",
    "\n",
    "pickle_file = \"/Users/ruth/6.2050/fpga-project/nn_Asmbnn.pkl\"\n",
    "\n",
    "if(True):\n",
    "    data = {'m': m, 's': s, 'A': nn_A, 'b': b, 'nn': weights}\n",
    "\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {pickle_file}.\")\n",
    "else:\n",
    "    with open('/Users/ruth/6.2050/fpga-project/Asm.pkl', 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "\n",
    "    A = loaded_data[\"A\"]\n",
    "    s = loaded_data[\"s\"]\n",
    "    m = loaded_data[\"m\"]\n",
    "\n",
    "def make_num(list, bits):\n",
    "    number = 0\n",
    "    #for i, val in enumerate(reversed(list)):\n",
    "        #number += (val << i*bits)\n",
    "    for i, val in enumerate(list):\n",
    "        number += (val << i*bits)\n",
    "    return number\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/A.mem', 'w') as f:\n",
    "    for x in range(N):\n",
    "        for y in range(0, k+2, 2):\n",
    "            f.write(f'{make_num(nn_A[x][y:y+2], 16):X}\\n')\n",
    "print('Output image saved at A.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/s.mem', 'w') as f:\n",
    "    for y in range(0, k, 2):\n",
    "        f.write(f'{make_num(s[y:y+2], 1):X}\\n')\n",
    "print('Output image saved at s.mem')\n",
    "\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/pt.mem', 'w') as f:\n",
    "    for y in range(0, N):\n",
    "        f.write(f'{make_num([m[y]], 1):X}\\n')\n",
    "print('Output image saved at pt.mem')\n",
    "\n",
    "b = b.astype(int)\n",
    "with open(f'/Users/ruth/6.2050/fpga-project/lab03/data/b.mem', 'w') as f:\n",
    "    for x in range(2510):\n",
    "        f.write(f'{0:X}\\n')\n",
    "print('Output image saved at b.mem')\n",
    "\n",
    "print(b)\n",
    "print(nn_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52774 37069 17388 ... 21463 24426 45582]\n",
      " [15765  3787 62161 ... 14539 63898 50982]\n",
      " [44216  8382 12056 ...   696 27930 11808]\n",
      " ...\n",
      " [43045 44433  2966 ...   666 41177 53506]\n",
      " [50853 41238  4730 ... 27675 48747 61899]\n",
      " [  525 32797 36581 ... 54958 13186 40604]]\n",
      "[[36237.]\n",
      " [64280.]\n",
      " [24134.]\n",
      " [12073.]\n",
      " [37135.]\n",
      " [27133.]\n",
      " [45598.]\n",
      " [ 6287.]\n",
      " [56726.]\n",
      " [ 8956.]]\n",
      "(100, 502)\n"
     ]
    }
   ],
   "source": [
    "print(newA)\n",
    "print(newB)\n",
    "\n",
    "print(nn_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36045.],\n",
       "       [64408.],\n",
       "       [23942.],\n",
       "       [11945.],\n",
       "       [37071.],\n",
       "       [27069.],\n",
       "       [45470.],\n",
       "       [ 6287.],\n",
       "       [56470.],\n",
       "       [ 8764.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases = int8_quant[\"fc1.bias\"]\n",
    "bias_B = newB+biases.reshape(10, 1).astype(int)*2**6\n",
    "bias_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [11.],\n",
       "       [ 0.],\n",
       "       [13.],\n",
       "       [ 3.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [ 2.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_lwe(newA, bias_B, s, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  3,  3, 11,  0, 13,  3,  8,  9,  2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(weights, m) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([423.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec2(A[:, v].reshape(500, 1), [enc()[v]], s[:, v].reshape(500, 1), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T[v, :].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 6], [3, 5, 7], [4, 5, 3, 0]]\n"
     ]
    }
   ],
   "source": [
    "def sample_extraction(h = 0):\n",
    "\n",
    "    N = 2\n",
    "    k = 2\n",
    "\n",
    "    res_ct = [[1, 4, 6], [3, 5, 7]]\n",
    "    b = 0\n",
    "    h = 1\n",
    "\n",
    "    res_ct.append([0]*k*N)\n",
    "\n",
    "    for i in range(k):\n",
    "        for j in range(h+1): \n",
    "            res_ct[N][i+j] = res_ct[i][h-j]\n",
    "    for i in range(k):\n",
    "        for j in range(h+1, N): \n",
    "            res_ct[N][i+j] = res_ct[i][h-j + N]\n",
    "\n",
    "    print(res_ct)\n",
    "    b = b\n",
    "\n",
    "sample_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6205_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
