{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1 (Quantization here, training in quantize_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization code from Song Han's TinyML class\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max\n",
    "\n",
    "def get_quantization_scale_and_zero_point(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    get quantization scale for single tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [float] scale\n",
    "        [int] zero_point\n",
    "    \"\"\"\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    fp_max = fp_tensor.max()\n",
    "    fp_min = fp_tensor.min()\n",
    "\n",
    "    # scale\n",
    "    scale = (fp_max - fp_min) / (quantized_max - quantized_min)\n",
    "    # zero_point\n",
    "    zero_point = ((quantized_min - fp_min / scale))\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < quantized_min:\n",
    "        zero_point = quantized_min\n",
    "    elif zero_point > quantized_max:\n",
    "        zero_point = quantized_max\n",
    "    else: # convert from float to int using round()\n",
    "        zero_point = round(zero_point)\n",
    "    return scale, int(zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_quantize(fp_tensor, bitwidth, scale, zero_point, dtype=np.int8) -> np.array:\n",
    "    \"\"\"\n",
    "    linear quantization for single fp_tensor\n",
    "      from\n",
    "        r = fp_tensor = (quantized_tensor - zero_point) * scale\n",
    "      we have,\n",
    "        q = quantized_tensor = int(round(fp_tensor / scale)) + zero_point\n",
    "    :param tensor: [np.array] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :param scale: [float] scaling factor\n",
    "    :param zero_point: [int] the desired centroid of tensor values\n",
    "    :return:\n",
    "        [np.array] quantized tensor whose values are integers\n",
    "    \"\"\"\n",
    "    # assert(fp_tensor is np.array)\n",
    "    assert(isinstance(scale, float))\n",
    "    assert(isinstance(zero_point, int))\n",
    "\n",
    "    # scale the fp_tensor\n",
    "    scaled_tensor = fp_tensor/scale\n",
    "    # round the floating value to integer value\n",
    "    rounded_tensor = (np.round(scaled_tensor)) #.to(torch.int8)\n",
    "\n",
    "    # print(rounded_tensor.dtype)\n",
    "\n",
    "    # shift the rounded_tensor to make zero_point 0\n",
    "    shifted_tensor = rounded_tensor + zero_point\n",
    "\n",
    "    # clamp the shifted_tensor to lie in bitwidth-bit range\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    quantized_tensor = shifted_tensor.clip(quantized_min, quantized_max)\n",
    "    quantized_tensor = quantized_tensor.astype(np.int8)\n",
    "    return quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_quantize_feature(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    linear quantization for feature tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating feature to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [torch.(cuda.)Tensor] quantized tensor\n",
    "        [float] scale tensor\n",
    "        [int] zero point\n",
    "    \"\"\"\n",
    "    scale, zero_point = get_quantization_scale_and_zero_point(fp_tensor, bitwidth)\n",
    "    quantized_tensor = linear_quantize(fp_tensor, bitwidth, scale, zero_point)\n",
    "    return quantized_tensor, scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./NN/mnist_01_100_2.pt\")\n",
    "# checkpoint = torch.load(\"./NN/MNIST_12_layers.pt\")\n",
    "\n",
    "weights_biases = {}\n",
    "\n",
    "for name, param in checkpoint.items():\n",
    "    weights_biases[name] = param.cpu().numpy()  # Convert to numpy array and store\n",
    "\n",
    "int8_quant = {}\n",
    "\n",
    "for key in weights_biases:\n",
    "    print(key)\n",
    "    int8_quant[key] = linear_quantize_feature(weights_biases[key], 3)[0]\n",
    "    # print(int8_quant[key].shape)\n",
    "    # print(weights_biases[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(input):\n",
    "    layer1 = np.dot(weights_biases[\"fc1.weight\"], input) + weights_biases[\"fc1.bias\"]\n",
    "    # layer2 = np.dot(weights_biases[\"fc2.weight\"], layer1) + weights_biases[\"fc2.bias\"]\n",
    "    # layer3 = np.dot(weights_biases[\"fc3.weight\"], layer2) + weights_biases[\"fc3.bias\"]\n",
    "    return np.argmax(layer1)\n",
    "\n",
    "def run_quantized_nn(input):\n",
    "    layer1 = np.dot(int8_quant[\"fc1.weight\"], input) + int8_quant[\"fc1.bias\"]\n",
    "    # layer2 = np.dot(int8_quant[\"fc2.weight\"], layer1) + int8_quant[\"fc2.bias\"]\n",
    "    # layer3 = np.dot(int8_quant[\"fc3.weight\"], layer2) + int8_quant[\"fc3.bias\"]\n",
    "    return np.argmax(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_numpy_arr(fp):\n",
    "  img = Image.open(fp)\n",
    "\n",
    "  # Convert the image to grayscale\n",
    "  img = img.convert(\"L\")\n",
    "\n",
    "  pixel_values = np.array(img)\n",
    "\n",
    "  img_flattened = pixel_values.reshape(-1)\n",
    "\n",
    "  img_flattened = [0 if x > 127 else 1 for x in img_flattened]\n",
    "\n",
    "  return np.array(img_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img_flat):\n",
    "    for i in range(1):\n",
    "        flattened_tensor = img_flat  # Replace with your actual data\n",
    "\n",
    "        # Reshape to 28 x 28\n",
    "        image_tensor = flattened_tensor.reshape(28, 28)  # or .reshape(28, 28)\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(image_tensor, cmap=\"gray\")\n",
    "        plt.colorbar()  # Optional: to show the color scale\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = \"./images/7.png\"\n",
    "\n",
    "flat_image = convert_img_to_numpy_arr(fp)\n",
    "display_image(flat_image)\n",
    "print(run_nn(flat_image))\n",
    "run_quantized_nn(flat_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 64}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.Resize((10, 10)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Lambda(lambda x: torch.where(x > 0.7, torch.tensor(1.0), torch.tensor(0.0))),\n",
    "        transforms.Lambda(lambda x: x.view(-1))\n",
    "        ])\n",
    "\n",
    "def filter_0_and_1(dataset):\n",
    "    indices = [i for i, target in enumerate(dataset.targets) if target == 0 or target == 1]\n",
    "    dataset.targets = dataset.targets[indices]\n",
    "    dataset.data = dataset.data[indices]\n",
    "    return dataset\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "test_dataset = filter_0_and_1(test_dataset)\n",
    "\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "dataset2 = filter_0_and_1(dataset2)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "total = 900\n",
    "correct = 0\n",
    "\n",
    "for i in range(900):\n",
    "    img = test_dataset[i][0]\n",
    "    #display_image(img)\n",
    "    label = test_dataset[i][1]\n",
    "    # print(run_nn(img))\n",
    "    # print(run_quantized_nn(img))\n",
    "    if run_quantized_nn(img) == label:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAASiElEQVR4nO3db4xc1X3G8e9jA2oBq5i6UMt2igvuH7cqhroGibR1ipKueVGDVFqbijgIdUHCVZDyAsSLglRVok0gIaqDtcAKIxEsJExwkRsHobQmSkG2kYttXGDluLDYsrulCiRRhMz++uLepbMzszOzM3fm3rP7fKTRzv0zZ46vZ58999xzzygiMDNLyYKyK2BmNlsOLjNLjoPLzJLj4DKz5Di4zCw5Di4zS46Dy8z6RtKopDOSjsywXZK+KWlM0huSru6kXAeXmfXTk8BQi+0bgFX5Yxh4tJNCHVxm1jcRsQ/4oMUuG4GnIvMqcJGkpe3KPaeoCnZCkofpm/VZRKiX1w8NDcXExERH+x48ePAo8POaVSMRMTKLt1sGvFezPJ6vO9XqRT0Fl6Qh4BFgIfB4RDzYS3lmVr6JiQn279/f0b4LFiz4eUSs7eHtmoVs2wZO16eKkhYC28jOUVcDmyWt7rY8M6uOiOjoUYBxYEXN8nLgZLsX9dLHtQ4Yi4jjEfExsJPsfNXMEjfA4NoNfDG/ungt8OOIaHmaCL2dKjY7N72mfidJw2RXC8wsAQWGEpKeAdYDSySNA/cD5+bvsx3YA9wAjAE/A27rpNxegqujc9O8o24E3DlvlorJyclCyomIzW22B3DXbMvtJbi6Ojc1s+qr+jx9vfRx7QdWSVop6TxgE9n5qpklboB9XF3pusUVEWclbQX2kg2HGI2Io4XVzMxKUXYodaKncVwRsYesc83M5pA5HVxmNjc5uMwsOUVdVewXB5eZTTPn+7jMbG5ycJlZchxcZpYcB5eZJSUi3DlvZulxi8vMkuPgMrPkOLjMLCkex2VmSXJwmVlyfFXRzJLjFpeZJcV9XGaWJAeXmSXHwWVmyXFwmVlSfK+imSXJLS4zS46Dy8yS4+Ays+Q4uMwsKe6cN7MkucVlZslxcJlZchxcZpYU32RtZklycFnPqv4hakVS2VWwLszpq4qSTgAfAZ8AZyNibRGVMrNyVf2P5YICyvhcRKxxaJnNDVN9XJ08OiFpSNJbksYk3dtk+y9J+mdJ/yHpqKTb2pVZRHCZ2RxTVHBJWghsAzYAq4HNklbX7XYX8GZEXAmsBx6SdF6rcnsNrgC+J+mgpOEZKj4s6YCkAz2+l5kNSIEtrnXAWEQcj4iPgZ3Axvq3AxYp6xC9EPgAONuq0F4756+LiJOSLgFekvSfEbFvWo0iRoARAEnVPnE2M2BWfVxL6holI/nv/JRlwHs1y+PANXVl/BOwGzgJLAL+MiJaXh3oKbgi4mT+84yk58nSdV/rV5lZlc3yXsWJNv3bzS4r16finwKHgD8BLidrBL0SER/OVGjXp4qSLpC0aOo58AXgSLflmVl1FHiqOA6sqFleTtayqnUbsCsyY8CPgN9qVWgvLa5LgefzcTrnAN+OiO/2UN6cVfVLy/1U5r/dY8i6V+D/235glaSVwPvAJuCWun3eBa4HXpF0KfCbwPFWhXYdXBFxHLiy29ebWXUVFVwRcVbSVmAvsBAYjYijku7Mt28H/g54UtJhslPLeyJiolW5HjlvZg2KbClHxB5gT9267TXPT5J1NXXMwWVm03giQTNLUtX7ZR1cZtbAwWVmyXFwmZWk1S+fh0rMzBMJmlmSHFxmlhxfVTSz5LjFZWZJcR+XmSXJwWVmyXFwmVlyHFzWd1Uek1TVX4B29aryMe0336toZkmq6h+cKQ4uM2vg4DKz5Di4zCw5Di4zS4o7580sSW5xmVlyHFzzQNX/k63RfB6n1Ymqf6YdXGY2jW+yNrMkObjMLDm+qmhmyXGLy8yS4j4uM0uSg8vMkuPgmgfajQnq94egzO8PrPIH3GO1ulfl/1eABe12kDQq6YykIzXrLpb0kqR38p+L+1tNMxuUqXsVO3mUpW1wAU8CQ3Xr7gVejohVwMv5spnNEVMd9O0eZWkbXBGxD/igbvVGYEf+fAdwY7HVMrMyVT24uu3jujQiTgFExClJl8y0o6RhYLjL9zGzElS9j6vvnfMRMQKMAEiq9tEws9JbU53opI+rmdOSlgLkP88UVyUzK1uRnfOShiS9JWlMUtP+cEnrJR2SdFTSv7Urs9vg2g1syZ9vAV7oshwzq6Ci+rgkLQS2ARuA1cBmSavr9rkI+BbwZxHxO8DN7cpte6oo6RlgPbBE0jhwP/Ag8Kyk24F3O3kjK0fVm/yteBxWeQr83KwDxiLiOICknWQX996s2ecWYFdEvJu/d9szuLbBFRGbZ9h0fbvXmll6ZtnHtUTSgZrlkbxfe8oy4L2a5XHgmroyfgM4V9K/AouARyLiqVZv6pHzZtZgFsE1ERFrW2xv1myuL/wc4PfJGkO/CPy7pFcj4u2ZCnVwmVmDAk8Vx4EVNcvLgZNN9pmIiJ8CP5W0D7gSmDG4uu2cN7M5rMCrivuBVZJWSjoP2ER2ca/WC8AfSjpH0vlkp5LHWhXqFpeZTVPkOK6IOCtpK7AXWAiMRsRRSXfm27dHxDFJ3wXeACaBxyPiyMylOrjMrIkir0ZHxB5gT9267XXLXwW+2mmZDq4BKHvam6rycIfqqvpn0sFlZg0cXGaWlKn5uKrMwWVmDdziMrPkOLjMLDkOLjNLjoPLzJKSwkSCDq4K6HU8U9U/ZJYeX1U0s+RU/Y+hg8vMGji4zCwp7uMysyQ5uMwsOQ4uM0uOryqaWVLcx2XWQq+/HJ7Pq38cXGaWHAeXmSXHwWVmSfFEgmaWJLe4zCw5Di4zS46Dy8yS4+CynlX9Q1SWdsfF47y6k8IA1AXtdpA0KumMpCM16x6Q9L6kQ/njhv5W08wGaXJysqNHWdoGF/AkMNRk/dcjYk3+2NNku5klaqrV1e5RlranihGxT9JlA6iLmVVE8qeKLWyV9EZ+Krl4pp0kDUs6IOlAD+9lZgPSaWurzHDrNrgeBS4H1gCngIdm2jEiRiJibUSs7fK9zGzAqh5cXV1VjIjTU88lPQa8WFiNzKx0VT9V7Cq4JC2NiFP54k3AkVb7m1lakr9XUdIzwHpgiaRx4H5gvaQ1QAAngDv6V0Xrp36PdSrzL3er9/YYr5mVfRrYiU6uKm5usvqJPtTFzCoi+eAys/mn6sHVy3AIM5ujiryqKGlI0luSxiTd22K/P5D0iaQ/b1emW1xmNk2REwlKWghsAz4PjAP7Je2OiDeb7PcPwN5OynWLy8waFNjiWgeMRcTxiPgY2AlsbLLf3wDPAWc6KdTBZWYNZhFcS6bujMkfw3VFLQPeq1kez9d9StIysmFV2zutn08VK6CfHaFlX/bv5f37eVw8JU5rszj2E23uiml2IOsL/wZwT0R80ulxd3CZWYMC/2iMAytqlpcDJ+v2WQvszENrCXCDpLMR8Z2ZCnVwmdk0BQ9A3Q+skrQSeB/YBNxS934rp55LehJ4sVVogYPLzJoo6qpiRJyVtJXsauFCYDQijkq6M9/ecb9WLQeXmTUosn8xn2h0T926poEVEV/qpEwHl5k1qPrIeQeXmU0zJ26yNrP5x8Fl1qV2Y3qq/suVsqofWweXmTVIfiJBM5tf3MdlZklycJlZchxcZpYcB5eZJaXIiQT7xcFlZg3c4rK+fwjm+9xRVjwHl5klx8FlZknxOC4zS5KDy8yS46uKZpYct7jMLCnu4zKzJFU9uNp+IaykFZK+L+mYpKOSvpyvv1jSS5LeyX8u7n91zWwQCvwm677o5JuszwJfiYjfBq4F7pK0GrgXeDkiVgEv58tmNgdMTk529ChL2+CKiFMR8Xr+/CPgGNlXaG8EduS77QBu7FMdzWyAOm1tldnimlUfl6TLgKuA14BLI+IUZOEm6ZLiq2dmZah6H1fHwSXpQuA54O6I+LDT++MkDQPD3VXPzMowJ4JL0rlkofV0ROzKV5+WtDRvbS0FzjR7bUSMACN5OdU+GmYGVD+4OrmqKOAJ4FhEPFyzaTewJX++BXih+OqZWRnmQh/XdcCtwGFJh/J19wEPAs9Kuh14F7i5LzWcA/r9NVutXp/ylDdV/6s/V82JiQQj4gfATJ/+64utjplVQdX/aHjkvJk1cHCZWXIcXGaWlLI73jvh4DKzBg4uM0tO8lcVzWz+qXqLq5PZIazPJLV89GI2N8xW7dFP/TzmqSv6/0jSkKS3JI1JaphFRtJfSXojf/xQ0pXtynSLy8waFPWHQ9JCYBvweWAc2C9pd0S8WbPbj4A/joj/lbSB7BbBa1qV6+AyswYFtnjXAWMRcRxA0k6yKbE+Da6I+GHN/q8Cy9sV6uAyswaz6JxfIulAzfJIPrHClGXAezXL47RuTd0O/Eu7N3Vwmdk0s+xjnIiItS22N+swbFq4pM+RBddn272pg8vMGhR4qjgOrKhZXg6crN9J0u8BjwMbIuJ/2hXqq4pm1qDAq4r7gVWSVko6D9hENiXWpyR9BtgF3BoRb3dSqFtcZtagqBZXRJyVtBXYCywERiPiqKQ78+3bgb8Ffhn4Vj4U5Wyb0080yIFmngG1O1UfDFhV83U8VkT09A8///zz44orruho38OHDx9sFzL94BaXmU0zJyYSNLP5p+qtfAeXmTVwcJlZchxcZpYUTyRoZklycJlZcnxV0XrW7+9lTNV8Hac1CFX/TDm4zGwa93GZWZIcXGaWHAeXmSXHnfNmlhT3cZlZkhxcZpac5INL0grgKeBXgUmyyfAfkfQA8NfAf+e73hcRe/pVUZuZxzNZ0ZIPLuAs8JWIeF3SIuCgpJfybV+PiK/1r3pmVobkgysiTgGn8ucfSTpG9pVDZjYHpTCR4Ky+LEPSZcBVwGv5qq3512aPSlo8w2uGJR2o++41M6uwAr8soy86Di5JFwLPAXdHxIfAo8DlwBqyFtlDzV4XESMRsbaMeanNrDtVD66OripKOpcstJ6OiF0AEXG6ZvtjwIt9qaGZDVzV+7jatriUXbJ6AjgWEQ/XrF9as9tNwJHiq2dmg9Zpa6vqLa7rgFuBw5IO5evuAzZLWkP2ddongDv6UD8zK0HVW1ydXFX8AdBsoJDHbJnNUVW/quiR82bWIPkWl5nNL2X3X3XCwWVmDRxcZpYcB5eZJced82aWFPdxmVmSHFxmlhwHl5klx8FlZslxcJlZUubcRIJmNj8UOTuEpCFJb0kak3Rvk+2S9M18+xuSrm5XpoPLzBoUFVySFgLbgA3AarJZZVbX7bYBWJU/hskmKW3JwWVmDQpsca0DxiLieER8DOwENtbtsxF4KjKvAhfVzffXYNB9XBPAf9UsL8nXVVFV61bVeoHr1q0i6/ZrBZSxl6xOnfiFuu+TGImIkZrlZcB7NcvjwDV1ZTTbZxn5l/Q0M9DgiohfqV2WdKCqc9FXtW5VrRe4bt2qWt0iYqjA4prN5VffVOtkn2l8qmhm/TQOrKhZXg6c7GKfaRxcZtZP+4FVklZKOg/YBOyu22c38MX86uK1wI/z73OdUdnjuEba71KaqtatqvUC161bVa5bTyLirKStZP1mC4HRiDgq6c58+3ayaeBvAMaAnwG3tStXVR8ha2ZWz6eKZpYcB5eZJaeU4Gp3C0CZJJ2QdFjSobrxKWXUZVTSGUlHatZdLOklSe/kPxdXqG4PSHo/P3aHJN1QUt1WSPq+pGOSjkr6cr6+1GPXol6VOG4pGXgfV34LwNvA58kug+4HNkfEmwOtyAwknQDWRkTpgxUl/RHwE7JRxb+br/tH4IOIeDAP/cURcU9F6vYA8JOI+Nqg61NXt6XA0oh4XdIi4CBwI/AlSjx2Ler1F1TguKWkjBZXJ7cAGBAR+4AP6lZvBHbkz3eQffAHboa6VUJEnIqI1/PnHwHHyEZil3rsWtTLZqmM4JppeH9VBPA9SQclDZddmSYunRrjkv+8pOT61Nua3+E/WtZpbC1JlwFXAa9RoWNXVy+o2HGrujKCa9bD+wfsuoi4muyO9bvyUyLrzKPA5cAasvvMHiqzMpIuBJ4D7o6ID8usS60m9arUcUtBGcE16+H9gxQRJ/OfZ4DnyU5tq+T01J3z+c8zJdfnUxFxOiI+iYhJ4DFKPHaSziULh6cjYle+uvRj16xeVTpuqSgjuDq5BaAUki7IO02RdAHwBeBI61cN3G5gS/58C/BCiXWZpm4qkpso6dhJEvAEcCwiHq7ZVOqxm6leVTluKSll5Hx+ufcb/P8tAH8/8Eo0IenXyVpZkN0O9e0y6ybpGWA92RQjp4H7ge8AzwKfAd4Fbo6IgXeSz1C39WSnOwGcAO5od89Zn+r2WeAV4DAwNQfxfWT9SaUduxb12kwFjltKfMuPmSXHI+fNLDkOLjNLjoPLzJLj4DKz5Di4zCw5Di4zS46Dy8yS83+M9DTqjbXIrwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized NN answer:  8\n"
     ]
    }
   ],
   "source": [
    "img = test_dataset[i][0]\n",
    "display_image(img)\n",
    "print(\"Quantized NN answer: \", run_quantized_nn(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
