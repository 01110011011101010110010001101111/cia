{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1 (Quantization here, training in quantize_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization code from Song Han's TinyML class\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max\n",
    "\n",
    "def get_quantization_scale_and_zero_point(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    get quantization scale for single tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [float] scale\n",
    "        [int] zero_point\n",
    "    \"\"\"\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    fp_max = fp_tensor.max()\n",
    "    fp_min = fp_tensor.min()\n",
    "\n",
    "    # scale\n",
    "    scale = (fp_max - fp_min) / (quantized_max - quantized_min)\n",
    "    # zero_point\n",
    "    zero_point = ((quantized_min - fp_min / scale))\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < quantized_min:\n",
    "        zero_point = quantized_min\n",
    "    elif zero_point > quantized_max:\n",
    "        zero_point = quantized_max\n",
    "    else: # convert from float to int using round()\n",
    "        zero_point = round(zero_point)\n",
    "    return scale, int(zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_quantize(fp_tensor, bitwidth, scale, zero_point, dtype=np.int8) -> np.array:\n",
    "    \"\"\"\n",
    "    linear quantization for single fp_tensor\n",
    "      from\n",
    "        r = fp_tensor = (quantized_tensor - zero_point) * scale\n",
    "      we have,\n",
    "        q = quantized_tensor = int(round(fp_tensor / scale)) + zero_point\n",
    "    :param tensor: [np.array] floating tensor to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :param scale: [float] scaling factor\n",
    "    :param zero_point: [int] the desired centroid of tensor values\n",
    "    :return:\n",
    "        [np.array] quantized tensor whose values are integers\n",
    "    \"\"\"\n",
    "    # assert(fp_tensor is np.array)\n",
    "    assert(isinstance(scale, float))\n",
    "    assert(isinstance(zero_point, int))\n",
    "\n",
    "    # scale the fp_tensor\n",
    "    scaled_tensor = fp_tensor/scale\n",
    "    # round the floating value to integer value\n",
    "    rounded_tensor = (np.round(scaled_tensor)) #.to(torch.int8)\n",
    "\n",
    "    # print(rounded_tensor.dtype)\n",
    "\n",
    "    # shift the rounded_tensor to make zero_point 0\n",
    "    shifted_tensor = rounded_tensor + zero_point\n",
    "\n",
    "    # clamp the shifted_tensor to lie in bitwidth-bit range\n",
    "    quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "    quantized_tensor = shifted_tensor.clip(quantized_min, quantized_max)\n",
    "    quantized_tensor = quantized_tensor.astype(np.int8)\n",
    "    return quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_quantize_feature(fp_tensor, bitwidth):\n",
    "    \"\"\"\n",
    "    linear quantization for feature tensor\n",
    "    :param fp_tensor: [torch.(cuda.)Tensor] floating feature to be quantized\n",
    "    :param bitwidth: [int] quantization bit width\n",
    "    :return:\n",
    "        [torch.(cuda.)Tensor] quantized tensor\n",
    "        [float] scale tensor\n",
    "        [int] zero point\n",
    "    \"\"\"\n",
    "    scale, zero_point = get_quantization_scale_and_zero_point(fp_tensor, bitwidth)\n",
    "    quantized_tensor = linear_quantize(fp_tensor, bitwidth, scale, zero_point)\n",
    "    return quantized_tensor, scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "[[  0  -8   6 ...  -2 -14  13]\n",
      " [  1   5   4 ...   0 -12  11]\n",
      " [ -6   4  -5 ... -14  -1  -8]\n",
      " ...\n",
      " [  9  -3   5 ... -12   5  12]\n",
      " [  1  -9  -7 ...   6   5   4]\n",
      " [ -2  -2  -7 ...  -5   7  -2]]\n",
      "fc1.bias\n",
      "[ 108   32   89  -55   68   23   -4 -128   34  127]\n",
      "fc2.weight\n",
      "[[   8   16   22   85  -25  -10   37  -58   -3 -128]\n",
      " [  37  -63  -29  -87   -8   92  -72 -102  -57   49]\n",
      " [  12  -34  -32  -85  -84   38   74  -73  -91 -101]\n",
      " [  20   31   81  -18  -45  -79   58   -9  -20  -42]\n",
      " [  79  -26   57 -102    7  -87   70  -52   22  127]\n",
      " [  -2  -65  -86  -19  101  -79   21   48  -57  -17]\n",
      " [  46   -1   47  -23  111   21 -102  -49   54  -87]\n",
      " [   9   32   28  -88  -34   65   18   63   72   -1]\n",
      " [  46   55  -14   32  -49   30   61  -64   66  -20]\n",
      " [  90  -89  -15  -21   42  -44   60   67   29  -51]]\n",
      "fc2.bias\n",
      "[  76  127   35  -72  -35   45   12 -128   21   86]\n",
      "fc3.weight\n",
      "[[  36  -96   81   35  -30   27  -60   32  -30   56]\n",
      " [ -71   12  -47  -43  -38  -56    6   27  -59 -125]\n",
      " [  33   48   56  -82 -123  -42   43   -2   45   -6]\n",
      " [  62  -20  -45   14   27 -122   26   12   88  -25]\n",
      " [ -73  -27 -101  -47   20   44   97   23  -73   94]\n",
      " [  11  -97  -53   35   22   25  -38  -80   20   -5]\n",
      " [  20   37    2  -48  -60   60   22 -128  -68   -1]\n",
      " [ -82  101   81   11  127  -28  -68    0    2   23]\n",
      " [ -42  -62  -77  -59  -61  -18 -117   -9  -39   -3]\n",
      " [ -87   19  -57  -81   72   45  -55   -1   25  -16]]\n",
      "fc3.bias\n",
      "[  -2  -30  -89  -26  -57  -43  -76  127 -128   32]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./NN/MNIST_3.pt\")\n",
    "\n",
    "weights_biases = {}\n",
    "\n",
    "for name, param in checkpoint.items():\n",
    "    weights_biases[name] = param.cpu().numpy()  # Convert to numpy array and store\n",
    "\n",
    "int8_quant = {}\n",
    "\n",
    "for key in weights_biases:\n",
    "    print(key)\n",
    "    int8_quant[key] = linear_quantize_feature(weights_biases[key], 8)[0]\n",
    "    print(int8_quant[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(input):\n",
    "    layer1 = np.dot(weights_biases[\"fc1.weight\"], input) + weights_biases[\"fc1.bias\"]\n",
    "    layer2 = np.dot(weights_biases[\"fc2.weight\"], layer1) + weights_biases[\"fc2.bias\"]\n",
    "    return np.argmax(layer2)\n",
    "\n",
    "def run_quantized_nn(input):\n",
    "    layer1 = np.dot(int8_quant[\"fc1.weight\"], input) + int8_quant[\"fc1.bias\"]\n",
    "    layer2 = np.dot(int8_quant[\"fc2.weight\"], layer1) + int8_quant[\"fc2.bias\"]\n",
    "    return np.argmax(layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_numpy_arr(fp):\n",
    "  img = Image.open(fp)\n",
    "\n",
    "  # Convert the image to grayscale\n",
    "  img = img.convert(\"L\")\n",
    "\n",
    "  pixel_values = np.array(img)\n",
    "\n",
    "  img_flattened = pixel_values.reshape(-1)\n",
    "\n",
    "  img_flattened = [0 if x > 127 else 1 for x in img_flattened]\n",
    "\n",
    "  return np.array(img_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img_flat):\n",
    "    for i in range(1):\n",
    "        flattened_tensor = img_flat  # Replace with your actual data\n",
    "\n",
    "        # Reshape to 28 x 28\n",
    "        image_tensor = flattened_tensor.reshape(28, 28)  # or .reshape(28, 28)\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(image_tensor, cmap=\"gray\")\n",
    "        plt.colorbar()  # Optional: to show the color scale\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = \"./images/9.png\"\n",
    "\n",
    "flat_image = convert_img_to_numpy_arr(fp)\n",
    "display_image(flat_image)\n",
    "print(run_nn(flat_image))\n",
    "run_quantized_nn(flat_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),  # Normalize to standard MNIST mean and std\n",
    "    transforms.Lambda(lambda x: torch.where(x > 0.5, torch.tensor(1.0), torch.tensor(0.0))),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "test_dataset = datasets.MNIST(root='../data', train=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = test_dataset[6][0]\n",
    "display_image(img)\n",
    "print(run_nn(img))\n",
    "run_quantized_nn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
